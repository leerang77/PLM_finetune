{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51a58f5",
   "metadata": {},
   "source": [
    "# Notebook for downloading and preparing data\n",
    "This notebook downloads labeled datasets and prepares them for training. The code is mostly copied from https://github.com/RSchmirler/data-repo_plm-finetune-eval with small adaptations where necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79d42bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to download and prepare data\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def download_data(url, file_name):\n",
    "    \"\"\"Download and prepare data from a zipped CSV file.\"\"\"\n",
    "    # Download the zip file\n",
    "    response = requests.get(url)\n",
    "    zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
    "    with zip_file.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "    # Rename 'target' column to 'label'\n",
    "    df = df.rename(columns={\"target\":\"label\"})\n",
    "\n",
    "    # Split the data into train, validation, and test sets\n",
    "    test = df[df.set==\"test\"]\n",
    "    train_valid_df = df[df.set!=\"test\"].reset_index(drop=True)\n",
    "\n",
    "    train=train_valid_df[train_valid_df.validation!=True].reset_index(drop=True)\n",
    "    valid=train_valid_df[train_valid_df.validation==True].reset_index(drop=True)\n",
    "\n",
    "    keep_columns = [\"sequence\",\"label\"]\n",
    "    return train[keep_columns], valid[keep_columns], test[keep_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe9b2b1",
   "metadata": {},
   "source": [
    "# Sequence Regression Example Data Preparation \n",
    "GB1 dataset from https://github.com/J-SNACKKB/FLIP\n",
    "\n",
    "\"The GB1 \"four\" variations set stems from a 2016 publication in which mutations at four sites (V39, D40, G41 and V54) were probed against a binding assay. The full WT GB1 sequence was never included in the dataset, so it was inferred from side chain A of PDB's 5LDE.\n",
    "\n",
    "`three_vs_rest`: `train` is wild type, all single, double & triple mutations, `test` is everything else.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b188001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size 5382\n",
      "validation dataset size: 598\n",
      "test dataset size: 11486\n"
     ]
    }
   ],
   "source": [
    "GB1_URL = 'https://github.com/J-SNACKKB/FLIP/raw/main/splits/gb1/splits.zip'\n",
    "GB1_FILENAME = 'splits/three_vs_rest.csv'\n",
    "GB1_train_df, GB1_valid_df, GB1_test_df = download_data(GB1_URL, GB1_FILENAME)\n",
    "\n",
    "# Print dataset info\n",
    "print(\"train dataset size\", GB1_train_df.size)\n",
    "print(\"validation dataset size:\", GB1_valid_df.size)\n",
    "print(\"test dataset size:\", GB1_test_df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c3f1b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYD...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGIDGEWTYD...</td>\n",
       "      <td>1.445905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGLDGEWTYD...</td>\n",
       "      <td>1.690164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGMDGEWTYD...</td>\n",
       "      <td>1.170550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVAGEWTYD...</td>\n",
       "      <td>2.401243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence     label\n",
       "0  MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYD...  1.000000\n",
       "1  MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGIDGEWTYD...  1.445905\n",
       "2  MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGLDGEWTYD...  1.690164\n",
       "3  MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGMDGEWTYD...  1.170550\n",
       "4  MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVAGEWTYD...  2.401243"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB1_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b01b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"training_data/gb1\", exist_ok=True)\n",
    "GB1_train_df.to_csv(\"training_data/gb1/gb1_seq_regression_train.csv\",index=False)\n",
    "GB1_valid_df.to_csv(\"training_data/gb1/gb1_seq_regression_validation.csv\",index=False)\n",
    "GB1_test_df.to_csv(\"training_data/gb1/gb1_seq_regression_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943776c1",
   "metadata": {},
   "source": [
    "# Sequence Classification Example Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5cfd15",
   "metadata": {},
   "source": [
    "Subcellular location dataset from https://github.com/J-SNACKKB/FLIP/tree/main/splits/scl\n",
    "\n",
    "\"\n",
    "The six SCL (SubCellularLocation) splits stems from a 2021 publication (based on a 2017 publication) and a 2022 publicaiton which aim at predicting protein subcellular location.\n",
    "\n",
    "The possible subcellular localizations (in the splits, assigned to TARGET) are Cytoplasm, Nucleus, Cell membrane, Mitochondrion, Endoplasmic reticulum, Lysosome/Vacuole, Golgi apparatus, Peroxisome, Extracellular and Plastid.\n",
    "\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7facf6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the zip file from GitHub\n",
    "SCL_URL = 'https://github.com/J-SNACKKB/FLIP/raw/main/splits/scl/splits.zip'\n",
    "SCL_FILENAME = 'splits/mixed_soft.csv'\n",
    "SCL_train_df, SCL_valid_df, SCL_test_df = download_data(SCL_URL, SCL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1ec58cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size 19006\n",
      "validation dataset size: 3356\n",
      "test dataset size: 5536\n",
      "                       train  validation  test\n",
      "label                                         \n",
      "Cell membrane            906         161   273\n",
      "Cytoplasm               1862         299   505\n",
      "Endoplasmic reticulum    594          95   173\n",
      "Extracellular           1322         243   393\n",
      "Golgi apparatus          238          48    70\n",
      "Lysosome/Vacuole         214          42    64\n",
      "Mitochondrion           1003         200   302\n",
      "Nucleus                 2752         476   806\n",
      "Peroxisome               101          23    30\n",
      "Plastid                  511          91   152\n"
     ]
    }
   ],
   "source": [
    "# Print dataset size\n",
    "print(\"train dataset size\", SCL_train_df.size)\n",
    "print(\"validation dataset size:\", SCL_valid_df.size)\n",
    "print(\"test dataset size:\", SCL_test_df.size)\n",
    "\n",
    "# Print label distribution\n",
    "# Create a DataFrame with label distributions for each split\n",
    "label_dist = pd.DataFrame({\n",
    "    'train': SCL_train_df['label'].value_counts().sort_index(),\n",
    "    'validation': SCL_valid_df['label'].value_counts().sort_index(),\n",
    "    'test': SCL_test_df['label'].value_counts().sort_index()\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "print(label_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1be98549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv files\n",
    "os.makedirs(\"training_data/scl\", exist_ok=True)\n",
    "SCL_train_df.to_csv(\"training_data/scl/scl_seq_classification_train.csv\",index=False)\n",
    "SCL_valid_df.to_csv(\"training_data/scl/scl_seq_classification_validation.csv\",index=False)\n",
    "SCL_test_df.to_csv(\"training_data/scl/scl_seq_classification_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee5364",
   "metadata": {},
   "source": [
    "# Token Regression Example Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9f5e0",
   "metadata": {},
   "source": [
    "AAV fitness dataset from https://github.com/J-SNACKKB/FLIP/tree/main/splits/aav\n",
    "We use two_vs_many split. \n",
    "\n",
    "\"\n",
    "The original sequence from the aav study is UniProt P03135. A copy of the wildtype sequence can be found in this folder as P03135.fasta On the reference sequence, mutations where introduced starting from region `[561, 588]`, which reflects the AA sequence: `DEEEIRTTNPVATEQYGSVSTNLQRGNR`.\n",
    "\n",
    "`two_vs_many`: train if in \"des\" with levenshtein_distance <= 2 , test if in \"des\" with levenshtein_distance > 2\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb85bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the zip file from GitHub\n",
    "AAV_URL = 'https://github.com/J-SNACKKB/FLIP/raw/main/splits/aav/splits.zip'\n",
    "AAV_FILENAME = 'splits/two_vs_many.csv'\n",
    "AAV_train_df, AAV_valid_df, AAV_test_df = download_data(AAV_URL, AAV_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "119b0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size 460104\n",
      "validation dataset size: 6362\n",
      "test dataset size: 101552\n",
      "                                            sequence     label\n",
      "0  MAADGYLPDWLEDTLSEGIRQWWKLKPGPPPPKPAERHKDDSRGLV... -6.824780\n",
      "1  MAADGYLPDWLEDTLSEGIRQWWKLKPGPPPPKPAERHKDDSRGLV... -6.500402\n",
      "2  MAADGYLPDWLEDTLSEGIRQWWKLKPGPPPPKPAERHKDDSRGLV...  0.900998\n",
      "3  MAADGYLPDWLEDTLSEGIRQWWKLKPGPPPPKPAERHKDDSRGLV... -4.843517\n",
      "4  MAADGYLPDWLEDTLSEGIRQWWKLKPGPPPPKPAERHKDDSRGLV... -6.566587\n"
     ]
    }
   ],
   "source": [
    "# Print dataset info\n",
    "print(\"train dataset size\", AAV_train_df.size)\n",
    "print(\"validation dataset size:\", AAV_valid_df.size)\n",
    "print(\"test dataset size:\", AAV_test_df.size)\n",
    "print(AAV_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5344116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv files\n",
    "os.makedirs(\"training_data/aav\", exist_ok=True)\n",
    "AAV_train_df.to_csv(\"training_data/aav/aav_token_regression_train.csv\",index=False)\n",
    "AAV_valid_df.to_csv(\"training_data/aav/aav_token_regression_validation.csv\",index=False)\n",
    "AAV_test_df.to_csv(\"training_data/aav/aav_token_regression_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c175fe",
   "metadata": {},
   "source": [
    "# Token Classification Data Preparation Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec260df",
   "metadata": {},
   "source": [
    "Secondary structure prediction from https://github.com/J-SNACKKB/FLIP/tree/main/splits/secondary_structure\n",
    "\n",
    "\"\n",
    "The secondary structure split stem from three different publications, cited at the end, which aims at predicting the conservation score of the residues of a protein sequence.\n",
    "\n",
    "This is a well-known dataset and it is used to validate the behavior of code and models. Only provided a sampled split for this purpose.\n",
    "\n",
    "There are 9712 proteins for training, 1080 proteins for validation and 648 proteins for testing.\n",
    "\n",
    "`sampled`: Randomly split sequences into train/test with 95/5% probability.\n",
    "\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "48719277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>mask</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1es5-A</td>\n",
       "      <td>VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...</td>\n",
       "      <td>0011111111111111111111111111111111111111111111...</td>\n",
       "      <td>CCCCCCCCCEEEEEECCCCCEEEEECCCCCECCHHHHHHHHHHHHH...</td>\n",
       "      <td>1es5-A SET=train VALIDATION=False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a6h-E</td>\n",
       "      <td>MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...</td>\n",
       "      <td>0111111111111111111111111111111111111111111111...</td>\n",
       "      <td>CCCCCHHHHHHHCCCHHHHHHHHHHHHHHHHHCCCCCCCCCCCCCC...</td>\n",
       "      <td>2a6h-E SET=train VALIDATION=False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b1a-P</td>\n",
       "      <td>MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...</td>\n",
       "      <td>0011111111111111111111111111111111111111111111...</td>\n",
       "      <td>CCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHCCCCHHHHHH...</td>\n",
       "      <td>5b1a-P SET=train VALIDATION=False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ehi-C</td>\n",
       "      <td>GTGSQGETLGEKWKKKLNQLSRKEFDLYKKSGITEVDRTEAKEGLK...</td>\n",
       "      <td>0000001111111111111111111111111111111111111111...</td>\n",
       "      <td>CCCCCCCCHHHHHHHHHHCCCHHHHHHHHHCCCEEEECHHHHHHHC...</td>\n",
       "      <td>5ehi-C SET=train VALIDATION=False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5egf-A</td>\n",
       "      <td>HHHHHHAVAKDSTESKSWEPFSLSPIKDPQALHAALCSKNVIPVTS...</td>\n",
       "      <td>0000000000000000011111111111111111111111111111...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHCCCCCCCC...</td>\n",
       "      <td>5egf-A SET=train VALIDATION=False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                                           sequence  \\\n",
       "0  1es5-A  VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...   \n",
       "1  2a6h-E  MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...   \n",
       "2  5b1a-P  MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...   \n",
       "3  5ehi-C  GTGSQGETLGEKWKKKLNQLSRKEFDLYKKSGITEVDRTEAKEGLK...   \n",
       "4  5egf-A  HHHHHHAVAKDSTESKSWEPFSLSPIKDPQALHAALCSKNVIPVTS...   \n",
       "\n",
       "                                                mask  \\\n",
       "0  0011111111111111111111111111111111111111111111...   \n",
       "1  0111111111111111111111111111111111111111111111...   \n",
       "2  0011111111111111111111111111111111111111111111...   \n",
       "3  0000001111111111111111111111111111111111111111...   \n",
       "4  0000000000000000011111111111111111111111111111...   \n",
       "\n",
       "                                               label  \\\n",
       "0  CCCCCCCCCEEEEEECCCCCEEEEECCCCCECCHHHHHHHHHHHHH...   \n",
       "1  CCCCCHHHHHHHCCCHHHHHHHHHHHHHHHHHCCCCCCCCCCCCCC...   \n",
       "2  CCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHCCCCHHHHHH...   \n",
       "3  CCCCCCCCHHHHHHHHHHCCCHHHHHHHHHCCCEEEECHHHHHHHC...   \n",
       "4  CCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHCCCCCCCC...   \n",
       "\n",
       "                             dataset  \n",
       "0  1es5-A SET=train VALIDATION=False  \n",
       "1  2a6h-E SET=train VALIDATION=False  \n",
       "2  5b1a-P SET=train VALIDATION=False  \n",
       "3  5ehi-C SET=train VALIDATION=False  \n",
       "4  5egf-A SET=train VALIDATION=False  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import tempfile\n",
    "\n",
    "# Download the zip file from GitHub\n",
    "SS_URL = 'https://github.com/J-SNACKKB/FLIP/raw/main/splits/secondary_structure/splits.zip'\n",
    "\n",
    "# The structure of this dataset is different, so we handle it separately. \n",
    "# Adapted from RSchmirler et al. \n",
    "\n",
    "response = requests.get(SS_URL)\n",
    "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
    "\n",
    "# Extract the fasta file to a temporary directory\n",
    "# Sequence File\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    zip_file.extract('splits/sequences.fasta', temp_dir)\n",
    "\n",
    "    # Load the fasta files\n",
    "    fasta_file = open(temp_dir + '/splits/sequences.fasta')\n",
    "    \n",
    "    # Load FASTA file using Biopython\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append([record.name, str(record.seq)])\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\"])\n",
    "\n",
    "# Mask File\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    zip_file.extract('splits/mask.fasta', temp_dir)\n",
    "\n",
    "    # Load the fasta files\n",
    "    fasta_file = open(temp_dir + '/splits/mask.fasta')\n",
    "    \n",
    "    # Load FASTA file using Biopython\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append([str(record.seq)])\n",
    "\n",
    "    # Add to dataframe\n",
    "    df = pd.concat([df, pd.DataFrame(sequences, columns=[\"mask\"])], axis=1) \n",
    "    \n",
    "# Label File\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    zip_file.extract('splits/sampled.fasta', temp_dir)\n",
    "\n",
    "    # Load the fasta files\n",
    "    fasta_file = open(temp_dir + '/splits/sampled.fasta')\n",
    "    \n",
    "    # Load FASTA file using Biopython\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "\n",
    "        sequences.append([str(record.seq), record.description])\n",
    "\n",
    "    # Add to dataframe\n",
    "    df = pd.concat([df, pd.DataFrame(sequences, columns=[ \"label\", \"dataset\"])], axis=1)  \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f364b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data split information\n",
    "df[\"validation\"]=df.dataset.str.split(\"=\").str[2]\n",
    "df[\"test\"]=df.dataset.apply(lambda s: s.split(\"=\")[1].split(\" \")[0]=='test')\n",
    "\n",
    "# str to bool\n",
    "df['validation'] = df['validation'].apply(lambda x: x == 'True')\n",
    "\n",
    "# Extract data split information\n",
    "df[\"dataset\"]=df.dataset.str.split(\"=\").str[1]\n",
    "df[\"dataset\"]=df.dataset.str.split(\" \").str[0]\n",
    "\n",
    "# Preprocess mask and label to lists\n",
    "# C is class 0, E is class 1, H is class 2\n",
    "df['label'] = df['label'].str.replace(\"C\",\"0\")\n",
    "df['label'] = df['label'].str.replace(\"E\",\"1\")\n",
    "df['label'] = df['label'].str.replace(\"H\",\"2\")\n",
    "\n",
    "# str to integer\n",
    "df['label'] = df['label'].apply(lambda x: [int(i) for i in x])\n",
    "df['mask'] = df['mask'].apply(lambda x: [int(i) for i in x])\n",
    "\n",
    "# Set masked positions to -100 in label for loss calculation\n",
    "df['label'] = df.apply(lambda row: [-100 if m == 0 else l for l, m in zip(row['label'], row['mask'])], axis=1)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "ss_test_df = df[df.test==True].reset_index(drop=True)[[\"sequence\",\"label\"]]\n",
    "ss_train_df = df[(df.test==False) & (df.validation==False)].reset_index(drop=True)[[\"sequence\",\"label\"]]\n",
    "ss_valid_df = df[(df.test==False) & (df.validation==True)].reset_index(drop=True)[[\"sequence\",\"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "10193640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size 19424\n",
      "validation dataset size: 2160\n",
      "test dataset size: 728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...</td>\n",
       "      <td>[-100, -100, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...</td>\n",
       "      <td>[-100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...   \n",
       "1  MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...   \n",
       "2  MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...   \n",
       "\n",
       "                                               label  \n",
       "0  [-100, -100, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...  \n",
       "1  [-100, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, ...  \n",
       "2  [-100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset info\n",
    "print(\"train dataset size\", ss_train_df.size)\n",
    "print(\"validation dataset size:\", ss_valid_df.size)\n",
    "print(\"test dataset size:\", ss_test_df.size)\n",
    "\n",
    "# Show examples\n",
    "ss_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "792965c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv files\n",
    "os.makedirs(\"training_data/ss\", exist_ok=True)\n",
    "ss_train_df.to_csv(\"training_data/ss/ss_token_classification_train.csv\",index=False)\n",
    "ss_valid_df.to_csv(\"training_data/ss/ss_token_classification_validation.csv\",index=False)\n",
    "ss_test_df.to_csv(\"training_data/ss/ss_token_classification_test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
